{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959d351-bf9d-4e14-8190-deb5a4331200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs/PPO1\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 559      |\n",
      "|    ep_rew_mean     | 343      |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 266         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014694483 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | -0.00168    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 421         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 488        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817371 |\n",
      "|    clip_fraction        | 0.0466     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.17      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.9       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00355   |\n",
      "|    value_loss           | 81.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 485         |\n",
      "|    ep_rew_mean          | 252         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010291081 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 486         |\n",
      "|    ep_rew_mean          | 241         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010426344 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Logging to logs/PPO1\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 489      |\n",
      "|    ep_rew_mean     | 244      |\n",
      "| time/              |          |\n",
      "|    fps             | 67       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 494          |\n",
      "|    ep_rew_mean          | 248          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 285          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079207625 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.5         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 506         |\n",
      "|    ep_rew_mean          | 258         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009632828 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 509         |\n",
      "|    ep_rew_mean          | 258         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013913764 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 512        |\n",
      "|    ep_rew_mean          | 302        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 799        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00841329 |\n",
      "|    clip_fraction        | 0.0776     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2         |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.8       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00377   |\n",
      "|    value_loss           | 107        |\n",
      "----------------------------------------\n",
      "Logging to logs/PPO1\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 516      |\n",
      "|    ep_rew_mean     | 311      |\n",
      "| time/              |          |\n",
      "|    fps             | 74       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 520         |\n",
      "|    ep_rew_mean          | 338         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036503 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 334         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.utils import play\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "models_dir =  \"models/PPO1\"\n",
    "logdir = \"logs/PPO1\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "env = gym.make(\"ALE/MsPacman-v5\")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log = logdir)\n",
    "TIMESTEPS = 10000\n",
    "\n",
    "for i in range(1, 100):\n",
    "    model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name = \"PPO\")\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")\n",
    "    \n",
    "env.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5070a-58d0-4687-9cdb-41f0fb978d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
