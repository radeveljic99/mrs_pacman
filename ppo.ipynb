{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb295b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs/PPO\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 480      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    fps             | 110      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 502        |\n",
      "|    ep_rew_mean          | 241        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01135606 |\n",
      "|    clip_fraction        | 0.0686     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.19      |\n",
      "|    explained_variance   | 0.0022     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.6       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00204   |\n",
      "|    value_loss           | 99.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 498          |\n",
      "|    ep_rew_mean          | 238          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063885394 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000815    |\n",
      "|    value_loss           | 83           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 503         |\n",
      "|    ep_rew_mean          | 241         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742728 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 523         |\n",
      "|    ep_rew_mean          | 282         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011112025 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "Logging to logs/PPO\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 516      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 522          |\n",
      "|    ep_rew_mean          | 294          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072326725 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.6         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 97.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 531         |\n",
      "|    ep_rew_mean          | 301         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007169999 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 937         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 307         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 629         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015065903 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 544         |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009564608 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "Logging to logs/PPO\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 539      |\n",
      "|    ep_rew_mean     | 309      |\n",
      "| time/              |          |\n",
      "|    fps             | 72       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | 318          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077737183 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.utils import play\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "models_dir =  \"models/PPO\"\n",
    "logdir = \"logs/PPO\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "env = gym.make(\"ALE/MsPacman-v5\")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log = logdir)\n",
    "TIMESTEPS = 10000\n",
    "\n",
    "for i in range(1, 100):\n",
    "    model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name = \"PPO\")\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")\n",
    "    \n",
    "env.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7fb29-6750-4ec0-8665-75712b427e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
